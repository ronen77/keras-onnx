{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "# !pip install keras2onnx\n",
    "# !pip install onnxruntime\n",
    "# !pip install onnxmltools\n",
    "# !pip install tf2onnx\n",
    "# !pip install tf2onnx onnx onnxruntime\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#second model imports\n",
    "from tensorflow.keras import datasets, layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "import onnxruntime\n",
    "import onnxmltools\n",
    "import keras2onnx\n",
    "\n",
    "import mlflow\n",
    "\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.75;background:#1e7b1e;padding-left:20px;padding-top:5px;padding-bottom:5px;border-radius:5px 5px 0px 0px\">\n",
    "<i style=\"font-size:40px;color:#c1f0c1;\">Global Functions and Variables</i>\n",
    "   \n",
    "</div>\n",
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:16px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "Global Functions and Variables, below you can find functions for building the models and the data<br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure to clean data_v1, data_v2 and dvc_repository directories before continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\working\\\\gitos\\\\keras-onnx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the current directory\n",
    "base_directory = %pwd\n",
    "base_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = 'models/'\n",
    "data_v1_path = 'data_v1/'\n",
    "data_v2_path = 'data_v2/'\n",
    "dvc_repository_path = 'dvc_repository'\n",
    "raw_data_path = 'raw_data/'\n",
    "mlflow_path = 'mlflow/'\n",
    "\n",
    "# os.listdir(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create_model\n",
    "#------------------------------\n",
    "\n",
    "def create_model_ver_1():\n",
    "    model = models.Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "# create_model version 2\n",
    "#------------------------------\n",
    "def create_model_ver_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(layers.Conv2D(256, (5, 5),padding='same', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2),padding=\"same\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(layers.Dense(256))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# prepare_data\n",
    "#------------------------------\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['Emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'Pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "\n",
    "# data_to_tf_data\n",
    "#-----------------------------\n",
    "\n",
    "def data_to_tf_data(df):\n",
    "    image_array, image_label = prepare_data(df)\n",
    "    images = image_array.reshape((image_array.shape[0], 48, 48, 1))\n",
    "    images = images.astype('float32')/255\n",
    "    labels = to_categorical(image_label)\n",
    "    return images, labels\n",
    "\n",
    "# plot_examples\n",
    "#-----------------------------\n",
    "\n",
    "def plot_examples(data,train_images,train_labels,  label=0):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(25, 12))\n",
    "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(5):\n",
    "        idx = data[data['Emotion']==label].index[i]\n",
    "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
    "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "# plot_all_emotions\n",
    "#-----------------------------        \n",
    "\n",
    "def plot_all_emotions(data,train_images, train_labels):\n",
    "    fig, axs = plt.subplots(1, 7, figsize=(30, 12))\n",
    "    fig.subplots_adjust(hspace = .2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(7):\n",
    "        idx = data[data['Emotion']==i].index[i]\n",
    "        axs[i].imshow(train_images[idx][:,:,0], cmap='gray')\n",
    "        axs[i].set_title(emotions[train_labels[idx].argmax()])\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "        \n",
    "\n",
    "# plot_image_and_emotion\n",
    "#------------------------------\n",
    "\n",
    "def plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, image_number):\n",
    "    \"\"\" Function to plot the image and compare the prediction results with the label \"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "    \n",
    "    bar_label = emotions.values()\n",
    "    \n",
    "    axs[0].imshow(test_image_array[image_number], 'gray')\n",
    "    axs[0].set_title(emotions[test_image_label[image_number]])\n",
    "    \n",
    "    axs[1].bar(bar_label, pred_test_labels[image_number], color='orange', alpha=0.7)\n",
    "    axs[1].grid()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# plot_compare_distributions\n",
    "#------------------------------\n",
    "\n",
    "def plot_compare_distributions(array1, array2, title1='', title2=''):\n",
    "    df_array1 = pd.DataFrame()\n",
    "    df_array2 = pd.DataFrame()\n",
    "    df_array1['emotion'] = array1.argmax(axis=1)\n",
    "    df_array2['emotion'] = array2.argmax(axis=1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6), sharey=False)\n",
    "    x = emotions.values()\n",
    "    \n",
    "    y = df_array1['emotion'].value_counts()\n",
    "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
    "    for key_missed in keys_missed:\n",
    "        y[key_missed] = 0\n",
    "    axs[0].bar(x, y.sort_index(), color='orange')\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].grid()\n",
    "    \n",
    "    y = df_array2['emotion'].value_counts()\n",
    "    keys_missed = list(set(emotions.keys()).difference(set(y.keys())))\n",
    "    for key_missed in keys_missed:\n",
    "        y[key_missed] = 0\n",
    "    axs[1].bar(x, y.sort_index())\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# save_to_onnx\n",
    "#------------------------------\n",
    "\n",
    "def save_to_onnx(model, output_onnx_model):\n",
    "    onnx_model_to_save = keras2onnx.convert_keras(model, model.name)\n",
    "    onnxmltools.utils.save_model(onnx_model_to_save, output_onnx_model)\n",
    "    print(f'Save model to {output_onnx_model} - Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.75;background:#1e7b1e;padding-left:20px;padding-top:5px;padding-bottom:5px;border-radius:5px 5px 0px 0px\"><i style=\"font-size:40px;color:#c1f0c1;\">Load and Prepare the Data</i>\n",
    "   \n",
    "</div>\n",
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:16px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "Load and Prepare the data, this part is intended for the first training of the model, the first \"fit\" command<br>\n",
    "Later in the main loop we load the data for each iteration\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since i had some issues with the initial training data i create my own initial training base on icml_face_data.csv\n",
    "\n",
    "## NO NEED TO RUN I DID IT ONCE \n",
    "\n",
    "# df = pd.read_csv(raw_data_path + 'initial_training_data.csv')\n",
    "# df.drop(' Usage',axis='columns', inplace=True)\n",
    "# df.rename(columns={'emotion': 'Emotion', ' pixels': 'Pixels'}, inplace=True)\n",
    "# df = df.sample(1000)\n",
    "# df.to_csv(raw_data_path + 'initial_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_data = pd.read_csv(raw_data_path + 'initial_training_data.csv')\n",
    "initial_train_images, initial_train_labels = data_to_tf_data(initial_train_data)\n",
    "\n",
    "validation_test_data = pd.read_csv(raw_data_path + 'validation_test_data.csv')\n",
    "validation_test_images, validation_test_labels = data_to_tf_data(validation_test_data)\n",
    "\n",
    "test_data = pd.read_csv(raw_data_path + 'test_data.csv')\n",
    "test_images, test_labels = data_to_tf_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.14641744548286603,\n",
       " 1: 0.006230529595015576,\n",
       " 2: 0.14953271028037382,\n",
       " 3: 0.2834890965732087,\n",
       " 4: 0.16822429906542055,\n",
       " 5: 0.09345794392523364,\n",
       " 6: 0.1526479750778816}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight = dict(zip(range(0, 7), (((initial_train_data['Emotion'].value_counts()).sort_index())/len(initial_train_data['Emotion'])).tolist()))\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.75;background:#1e7b1e;padding-left:20px;padding-top:5px;padding-bottom:5px;border-radius:5px 5px 0px 0px\">\n",
    "<i style=\"font-size:40px;color:#c1f0c1;\">Build and run the model</i>\n",
    "   \n",
    "</div>\n",
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:16px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "Build and run the model<br>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Model V1</b><br>\n",
    "</p>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                262208    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 318,407\n",
      "Trainable params: 318,407\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_v1 = create_model_ver_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "6/6 [==============================] - 2s 395ms/step - loss: 0.3222 - accuracy: 0.2523 - val_loss: 2.6649 - val_accuracy: 0.2449\n",
      "Epoch 2/12\n",
      "6/6 [==============================] - 2s 348ms/step - loss: 0.3352 - accuracy: 0.2835 - val_loss: 1.8812 - val_accuracy: 0.2449\n",
      "Epoch 3/12\n",
      "6/6 [==============================] - 2s 378ms/step - loss: 0.2952 - accuracy: 0.2835 - val_loss: 1.9188 - val_accuracy: 0.2449\n",
      "Epoch 4/12\n",
      "6/6 [==============================] - 2s 381ms/step - loss: 0.2987 - accuracy: 0.2835 - val_loss: 1.8943 - val_accuracy: 0.2449\n",
      "Epoch 5/12\n",
      "6/6 [==============================] - 2s 400ms/step - loss: 0.3030 - accuracy: 0.2835 - val_loss: 1.8894 - val_accuracy: 0.2458\n",
      "Epoch 6/12\n",
      "6/6 [==============================] - 3s 472ms/step - loss: 0.3046 - accuracy: 0.2991 - val_loss: 1.9414 - val_accuracy: 0.2455\n",
      "Epoch 7/12\n",
      "6/6 [==============================] - 2s 380ms/step - loss: 0.2980 - accuracy: 0.2835 - val_loss: 1.9059 - val_accuracy: 0.2449\n",
      "Epoch 8/12\n",
      "6/6 [==============================] - 2s 374ms/step - loss: 0.3030 - accuracy: 0.2835 - val_loss: 1.8469 - val_accuracy: 0.2449\n",
      "Epoch 9/12\n",
      "6/6 [==============================] - 2s 365ms/step - loss: 0.3009 - accuracy: 0.2835 - val_loss: 1.9710 - val_accuracy: 0.2449\n",
      "Epoch 10/12\n",
      "6/6 [==============================] - 2s 368ms/step - loss: 0.3031 - accuracy: 0.2835 - val_loss: 1.9971 - val_accuracy: 0.2452\n",
      "Epoch 11/12\n",
      "6/6 [==============================] - 2s 392ms/step - loss: 0.3010 - accuracy: 0.2773 - val_loss: 1.8542 - val_accuracy: 0.2438\n",
      "Epoch 12/12\n",
      "6/6 [==============================] - 2s 373ms/step - loss: 0.3049 - accuracy: 0.3084 - val_loss: 1.8576 - val_accuracy: 0.2497\n"
     ]
    }
   ],
   "source": [
    "history = model_v1.fit(initial_train_images, \n",
    "                    initial_train_labels,\n",
    "                    validation_data=(validation_test_images, validation_test_labels),\n",
    "                    class_weight = class_weight,\n",
    "                    epochs=12,\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 2s 17ms/step - loss: 1.8474 - accuracy: 0.2538\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_v1.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User6\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\User6\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model/model_v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model_v1.save('model/model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Model V2</b><br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 64)        128       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 48, 48, 256)       819456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               18874496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 19,806,087\n",
      "Trainable params: 19,804,423\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_v2 = create_model_ver_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6/6 [==============================] - 181s 30s/step - loss: 0.4119 - accuracy: 0.1776 - val_loss: 2.0123 - val_accuracy: 0.0485\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 162s 27s/step - loss: 0.3049 - accuracy: 0.3458 - val_loss: 1.9598 - val_accuracy: 0.1967\n"
     ]
    }
   ],
   "source": [
    "history = model_v2.fit(initial_train_images, \n",
    "                    initial_train_labels,\n",
    "                    validation_data=(validation_test_images, validation_test_labels),\n",
    "                    class_weight = class_weight,\n",
    "                    epochs=2,  #should be 12\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 120s 1s/step - loss: 1.9526 - accuracy: 0.1953\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_v2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_v2.save('model/model_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.75;background:#1e7b1e;padding-left:20px;padding-top:5px;padding-bottom:5px;border-radius:5px 5px 0px 0px\">\n",
    "<i style=\"font-size:40px;color:#c1f0c1;\">Create CI/CD</i>\n",
    "   \n",
    "</div>\n",
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:16px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "Create CI/CD<br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Replace between Model V1 and Model V2</b><br>\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\working\\gitos\\keras-onnx\n"
     ]
    }
   ],
   "source": [
    "%cd {base_directory}\n",
    "\n",
    "MODEL = model_v2\n",
    "model_version = 'model_v2'\n",
    "#%cd {data_v1_path}\n",
    "\n",
    "#MODEL = model_v2\n",
    "#%cd {data_v2_path}\n",
    "#model_version = 'model_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Build the mlflow</b><br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the mlflow - make sure to end the last run before starting new one\n",
    "mlflow.create_experiment(\"uatt\")\n",
    "mlflow.set_experiment(model_version)\n",
    "mlflow.log_param(\"Model name\", MODEL.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Init git and dvc</b><br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty Git repository in C:/working/gitos/keras-onnx/data_v1/.git/\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "[master (root-commit) 32a1f29] Initialize DVC\n",
      " 9 files changed, 515 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvc/plots/confusion.json\n",
      " create mode 100644 .dvc/plots/confusion_normalized.json\n",
      " create mode 100644 .dvc/plots/default.json\n",
      " create mode 100644 .dvc/plots/linear.json\n",
      " create mode 100644 .dvc/plots/scatter.json\n",
      " create mode 100644 .dvc/plots/smooth.json\n",
      " create mode 100644 .dvcignore\n",
      "Setting 'myrepo' as a default remote.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in mlruns/0/meta.yaml.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/meta.yaml.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in mlruns/1/meta.yaml.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 5866b86] init\n",
      " 8 files changed, 31 insertions(+)\n",
      " create mode 100644 mlruns/0/meta.yaml\n",
      " create mode 100644 mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/meta.yaml\n",
      " create mode 100644 mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/params/Model name\n",
      " create mode 100644 mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/tags/mlflow.source.name\n",
      " create mode 100644 mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/tags/mlflow.source.type\n",
      " create mode 100644 mlruns/1/a9c3428ea19a40c0a0dae62e0857bdb2/tags/mlflow.user\n",
      " create mode 100644 mlruns/1/meta.yaml\n"
     ]
    }
   ],
   "source": [
    "!git config --global user.email \"saharbnm@gmail.com\"\n",
    "!git config --global user.name \"Sahar BnM\"\n",
    "!git init\n",
    "!dvc init\n",
    "!git commit -m \"Initialize DVC\"\n",
    "!dvc remote add myRepo ..\\dvc_repository -d\n",
    "!git add .\n",
    "!git commit -m \"init\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Main loop run the flow on the selected Model</b><br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID a9c3428ea19a40c0a0dae62e0857bdb2 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f20760fa867d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\fluent.py\u001b[0m in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[0mexperiment_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_active_run_stack\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         raise Exception(\n\u001b[0m\u001b[0;32m    187\u001b[0m             (\n\u001b[0;32m    188\u001b[0m                 \u001b[1;34m\"Run with UUID {} is already active. To start a new run, first end the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID a9c3428ea19a40c0a0dae62e0857bdb2 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. load and merge the data\n",
    "# 2. create branch and push to the branch and dvc\n",
    "# 3. decide according to the score how to proceed drop or merge to master\n",
    "\n",
    "initial_train_data = pd.read_csv('../' + raw_data_path + 'initial_training_data.csv')\n",
    "initial_train_data.to_csv(\"merge_data.csv\")\n",
    "\n",
    "Last_score = 0\n",
    "Grace_error = 0.005\n",
    "\n",
    "for seq in range(7):\n",
    "    \n",
    "    #parameters\n",
    "    branch_name = 'branch_' + str(seq)\n",
    "    csv_file_name = 'data_gathered_at_' + str(seq) + '.csv'\n",
    "    commit_str = 'commit merge data of initial_training_data and ' + csv_file_name\n",
    "    \n",
    "    print(\"-------------------------------\")\n",
    "    print(f'Loop number {seq}: branch name {branch_name}, file to load {csv_file_name}')\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    #make sure u start from the master branch\n",
    "    !git checkout master\n",
    "    !dvc pull\n",
    "    \n",
    "    #load data and merge to the initial training\n",
    "    print(\"-------------------------------\")\n",
    "    initial_train_data = pd.read_csv(\"merge_data.csv\")\n",
    "    print(f'initial_train_data contain {len(initial_train_data)} samples')\n",
    "    train_data = pd.read_csv('../' + raw_data_path + csv_file_name)\n",
    "    print(f'train_data contain {len(train_data)} samples')\n",
    "    train_data = pd.concat([initial_train_data, train_data])\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    #create new branch\n",
    "    print(\"-------------------------------\")\n",
    "    print(f'Create new branch name {branch_name}')\n",
    "    print(\"-------------------------------\")\n",
    "    !git checkout -b {branch_name}\n",
    "    \n",
    "    #save the new file to /data directory\n",
    "    train_data.to_csv(\"merge_data.csv\")\n",
    "    train_data = pd.read_csv('merge_data.csv')\n",
    "    print(f'mergedt data contain {len(train_data)} samples')\n",
    "    \n",
    "    \n",
    "    !dvc add merge_data.csv\n",
    "    !dvc push merge_data.csv\n",
    "    !git add merge_data.csv.dvc\n",
    "    !git commit -m \"{commit_str}\"\n",
    "    \n",
    "    #prepare the data\n",
    "    print(\"-------------------------------\")\n",
    "    print(f'Prepare the data')\n",
    "    print(\"-------------------------------\")\n",
    "    initial_train_images, initial_train_labels = data_to_tf_data(train_data)\n",
    "    \n",
    "    #run the model\n",
    "    print(\"-------------------------------\")\n",
    "    print(f'run the model')\n",
    "    print(\"-------------------------------\")\n",
    "    history = MODEL.fit(initial_train_images, \n",
    "                    initial_train_labels,\n",
    "                    validation_data=(validation_test_images, validation_test_labels),\n",
    "                    class_weight = class_weight,\n",
    "                    epochs=2, # should be 12\n",
    "                    batch_size=64)\n",
    "    \n",
    "    test_loss, test_acc = MODEL.evaluate(test_images, test_labels)\n",
    "    print(\"-------------------------------\")\n",
    "    print(f'The score is {test_acc}')\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    !git checkout master\n",
    "    \n",
    "    if test_acc >= (Last_score - Grace_error):\n",
    "        print(\"-------------------------------\")\n",
    "        print(f'!!! Good score {test_acc} (last={Last_score}) merge {branch_name} to the master')\n",
    "        print(\"-------------------------------\")\n",
    "        !git merge {branch_name}\n",
    "        \n",
    "    else:\n",
    "        print(\"-------------------------------\")\n",
    "        print(f'!!! Bad score {test_acc} (last={Last_score}) delete {branch_name}')\n",
    "        print(\"-------------------------------\")\n",
    "    \n",
    "    if test_acc >= (Last_score - Grace_error):\n",
    "        Last_score = test_acc\n",
    "\n",
    "    print(\"-------------------------------\")\n",
    "    print(f'Deleting branch {branch_name}')\n",
    "    print(\"-------------------------------\")\n",
    "    !git branch -D {branch_name} \n",
    "    \n",
    "    #update the mlflow\n",
    "    mlflow.log_metric(key=\"Accuracy\", value=test_acc, step=seq)\n",
    "              \n",
    "    ### END OF LOOP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Run 'a9c3428ea19a40c0a0dae62e0857bdb2' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-603d83e8ad2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\fluent.py\u001b[0m in \u001b[0;36mend_run\u001b[1;34m(status)\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munset_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUN_ID_ENV_VAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_active_run_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0mMlflowClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_terminated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\client.py\u001b[0m in \u001b[0;36mset_terminated\u001b[1;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[0;32m   1407\u001b[0m             \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mKILLED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m         \"\"\"\n\u001b[1;32m-> 1409\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_terminated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdelete_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py\u001b[0m in \u001b[0;36mset_terminated\u001b[1;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mRunStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRunStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFINISHED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         self.store.update_run_info(\n\u001b[0m\u001b[0;32m    326\u001b[0m             \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_status\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRunStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\u001b[0m in \u001b[0;36mupdate_run_info\u001b[1;34m(self, run_id, run_status, end_time)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_run_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_status\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0m_validate_run_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mrun_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_run_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m         \u001b[0mcheck_run_is_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mnew_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copy_with_overrides\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_status\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\u001b[0m in \u001b[0;36m_get_run_info\u001b[1;34m(self, run_uuid)\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[0mexp_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_run_root\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_uuid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             raise MlflowException(\n\u001b[0m\u001b[0;32m    517\u001b[0m                 \u001b[1;34m\"Run '%s' not found\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrun_uuid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatabricks_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRESOURCE_DOES_NOT_EXIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             )\n",
      "\u001b[1;31mMlflowException\u001b[0m: Run 'a9c3428ea19a40c0a0dae62e0857bdb2' not found"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('merge_data.csv')\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_labels = MODEL.predict(test_images)\n",
    "pred_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"line-height:1.75;background:#1e7b1e;padding-left:20px;padding-top:5px;padding-bottom:5px;border-radius:5px 5px 0px 0px\">\n",
    "<i style=\"font-size:40px;color:#c1f0c1;\">Analyse Convergence</i>\n",
    "   \n",
    "</div>\n",
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:16px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "Analyse Convergence<br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, loss, 'bo', label='loss_train')\n",
    "plt.plot(epochs, loss_val, 'b', label='loss_val')\n",
    "plt.title('value of the loss function')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('value of the loss function')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "acc_val = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs, acc, 'bo', label='accuracy_train')\n",
    "plt.plot(epochs, acc_val, 'b', label='accuracy_val')\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('value of accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('merge_data.csv')\n",
    "test_image_array, test_image_label = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_and_emotion(test_image_array, test_image_label, pred_test_labels, 150)\n",
    "plot_compare_distributions(test_labels, pred_test_labels, title1='test labels', title2='predict labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pred_test_labels = model.predict(test_images)\n",
    "#np.around(pred_test_labels, decimals=4, out=None)\n",
    "print(pred_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(test_labels.argmax(axis=1), pred_test_labels.argmax(axis=1))\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=conf_mat,\n",
    "                                show_normed=True,\n",
    "                                show_absolute=False,\n",
    "                                class_names=emotions.values(),\n",
    "                                figsize=(8, 8))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(initial_train_data, initial_train_images, initial_train_labels,label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_emotions(initial_train_data, initial_train_images, initial_train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<p style=\"line-height:1.75;font-size:20px;background:#c1f0c1;padding:20px;border-radius:0px 0px 5px 5px\">\n",
    "<b>Save the notebook as html file</b><br>\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!jupyter nbconvert --to html Main_notebook_model_run.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
